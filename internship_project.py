# -*- coding: utf-8 -*-
"""Internship_Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d0h9kKS3RxzWr21--9UzPw7BQTQkT7ie

# **Importing Libraries**
"""

# ab ek last streamlit app m run krna h fr ppt ready krni h bs or app ke liye requirements sahi krne h github m internship wala sahi krna h

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import statistics
import math

"""#### **Loading a Dataset**"""

# Load dataset
tsv = pd.read_csv("/content/Order.tsv", sep = "\t")
print(tsv.shape)
tsv.head()

# Load dataset
json = pd.read_json("/content/Order_breakdown.json")
print(json.shape)
json.tail()

# Merge dataset in a new DataFrame
df = pd.concat([tsv, json], axis = 1, join = "inner")
print(df.shape)
df.head(3)
df["Sales"].max()

# Saving Merged Dataset
df.to_csv("merge_dataset.csv")

"""#### **Checking the Column Names**"""

# Checking the Column Names
df.columns

"""#### **Checking the datatypes of the columns**"""

# Checking the datatypes of the columns
df.dtypes

"""### **Change the Date Columns Datatype to Datetime Datatype**"""

# Change the Date Columns Datatype to Datetime
df["Order Date"] = pd.to_datetime(df["Order Date"])
df["Ship Date"] = pd.to_datetime(df["Ship Date"])
df.dtypes

"""#### **Checking the shape of the dataset**"""

# Checking the shape of the dataset
df.shape

"""Number of rows = 4117<br>
Number of columns = 20

#### **Checking the Null values (Data Cleaning)**
"""

# Checking the Null values
df.isnull().sum()

"""There are no null values present in our dataset

#### **Checking the duplicate values (Data Cleaning)**
"""

df.duplicated().sum()

"""There are no duplicates values in our dataset.

#### **Description of the columns**
"""

# Description of the numerical columns
df.describe()

"""#### **Information about columns**"""

# Short Information of all the columns
df.info()

"""### **Extract Month and Year from Order Date**"""

# Extract Month and Year from Order Date
df["Month"] = df["Order Date"].dt.month
df["Year"] = df["Order Date"].dt.year

"""# **Uni-Variate EDA**

#### **Extract Categorical Columns and Numerical Columns**
"""

cat_col = df.select_dtypes(include = object).columns
num_col = df.select_dtypes(exclude = object).columns
print("Categorical Columns: \n",cat_col)
print("Numerical Columns: \n",num_col)

"""#### **Value Count Plot of Categorical Columns**"""

print('Categorical Data: \n')

print('Category unique values: ', df['Category'].unique())
print('Number of unique values: ', df['Category'].unique().size,"\n")

print('Country unique values: ', df['Country'].unique())
print('Number of unique values: ', df['Country'].unique().size,"\n")

print('Segment unique values: ', df['Segment'].unique())
print('Number of unique values: ', df['Segment'].unique().size,"\n")

print('Sub-Category unique values: ', df['Sub-Category'].unique())
print('Number of unique values: ', df['Sub-Category'].unique().size)

# Value Counts of Categorical Columns
a2 = df["Category"].value_counts()
a3 = df["Country"].value_counts()
a4 = df["Segment"].value_counts()
a5 = df["Sub-Category"].value_counts()

print('Category unique values:\n', a2,"\n")
print('Country unique values:\n', a3,"\n")
print('Segment unique values:\n', a4,"\n")
print('Sub-Category unique values:\n', a5,"\n")

figure, axis = plt.subplots(2,2, figsize = (18, 17))

axis[0,1].barh(a2.index, a2.values, color = "orange", edgecolor = "Black")
axis[0,1].legend
axis[0,1].set_title("Category Count")

axis[1,0].barh(a3.index, a3.values, color = "green", edgecolor = "Black")
axis[1,0].legend
axis[1,0].set_title("Country Count")

axis[1,1].barh(a4.index, a4.values, color = "cyan", edgecolor = "Black")
axis[1,1].legend
axis[1,1].set_title("Segment Count")

axis[0,0].barh(a5.index, a5.values, color = "yellow", edgecolor = "Black")
axis[0,0].legend
axis[0,0].set_title("Sub Category Count")

plt.show()

a1 = df.groupby(["Category","Sub-Category"]).size()
a1.plot(kind = "barh", color = "m", edgecolor = "black")
plt.title("Category & Sub Category Count")
plt.show()

"""# **Bi-Variate EDA**

# **Bar Plot**
"""

s1 = df.groupby(["Country"])["Sales"].sum()
s1 = s1.sort_values(ascending = False).head()
s2 = df.groupby(["State"])["Sales"].sum()
s2 = s2.sort_values(ascending = False).head()
s3 = df.groupby(["City"])["Sales"].sum()
s3 = s3.sort_values(ascending = False).head()
s4 = df.groupby(["Region"])["Sales"].sum()
s4 = s4.sort_values(ascending = False).head()

figure, axis = plt.subplots(2,2, figsize = (15,12))

axis[1,0].barh(s1.index, s1.values, color = "red", edgecolor = "Black")
axis[1,0].set_ylabel("Country")
axis[1,0].set_xlabel("Sales")
axis[1,0].set_title("Top 5 Countries having highest sales")

axis[0,0].barh(s2.index, s2.values, color = "orange", edgecolor = "Black")
axis[0,0].set_ylabel("State")
axis[0,0].set_xlabel("Sales")
axis[0,0].set_title("Top 5 States having highest sales")

axis[0,1].barh(s3.index, s3.values, color = "green", edgecolor = "Black")
axis[0,1].set_ylabel("City")
axis[0,1].set_xlabel("Sales")
axis[0,1].set_title("Top 5 City having highest sales")

axis[1,1].barh(s4.index, s4.values, color = "cyan", edgecolor = "Black")
axis[1,1].set_ylabel("Region")
axis[1,1].set_xlabel("Sales")
axis[1,1].set_title("Region wise sales")


plt.show()

"""### **Q) In which year we have more Sales ?**"""

ax = sns.barplot(data = df, x = df["Year"], y = df["Sales"], errorbar = None)
ax.bar_label(ax.containers[0])
plt.title("Year wise Sales")
plt.show()

"""We can see that there is more sales in 2016

### **Q) In which month we have more Sales ?**
"""

plt.figure(figsize = (15,10))
sns.barplot(data = df, x = df["Month"], y = df["Sales"], errorbar = None, hue = "Year")
plt.title("Year and Month wise Sales")
plt.show()

"""In month 7 and year 2016 we have more sale

### **Q) In which month we have more Sales with specific year graph ?**
"""

s_2013 = df[df["Year"]==2013]
s_2014 = df[df["Year"]==2014]
s_2015 = df[df["Year"]==2015]
s_2016 = df[df["Year"]==2016]

fig, ax = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Sales by Year', fontsize=22)

sns.barplot(data = s_2013, x = s_2013["Month"], y = s_2013["Sales"], errorbar = None, ax = ax[0,0])
sns.barplot(data = s_2014, x = s_2014["Month"], y = s_2014["Sales"], errorbar = None, ax = ax[0,1])
sns.barplot(data = s_2015, x = s_2015["Month"], y = s_2015["Sales"], errorbar = None, ax = ax[1,0])
sns.barplot(data = s_2016, x = s_2016["Month"], y = s_2016["Sales"], errorbar = None, ax = ax[1,1])

ax[0,0].title.set_text('Year 2013')
ax[0,1].title.set_text('Year 2014')
ax[1,0].title.set_text('Year 2015')
ax[1,1].title.set_text('Year 2016')


plt.show()

"""### **Q) Which Category & Sub-Category makes more Sale ?**"""

sale_sc = df.groupby(["Sub-Category"])["Sales"].sum()
sale_sc = sale_sc.sort_values(ascending = False).head().to_frame()
colors = ["skyblue", "orange", "lightgreen", "m", "c"]

fig, ax = plt.subplots(2, figsize = (10,10))

sns.barplot(data = df, x = "Category", y = "Sales", hue = "Category", errorbar = None, ax = ax[0])
ax[1].bar(sale_sc.index, sale_sc["Sales"], color = colors, label = sale_sc.index)
ax[1].legend()
ax[1].set_xlabel("Sub-Category")
ax[1].set_ylabel("Sales")

ax[0].title.set_text('Sales by Category')
ax[1].title.set_text('Sales by Sub-Category')

plt.show()

"""Category Technology and Sub-Category Phones have highest sales

### **Top 5 Customers which have most sale**
"""

cus_sale = df.groupby(["Customer Name"])["Sales"].sum()
cus_sale = cus_sale.sort_values(ascending = False).head().to_frame()
sns.barplot(data = cus_sale, x = cus_sale["Sales"], y = cus_sale.index)
plt.title("Top 5 customers with most Sale")
plt.show()

"""### **Q) In which year we have  more profit ?**"""

ax = sns.barplot(data = df, x = df["Year"], y = df["Profit"], errorbar = None)
ax.bar_label(ax.containers[0])
plt.title("Year wise Profit")
plt.show()

"""It can be seen that there is most profit in 2014 and 2015 than in others.<br>
The profit is approximately the same in both the years (2014 & 2015)

### **Q) In which month we have more profit ?**
"""

plt.figure(figsize = (15,10))
sns.barplot(data = df, x = df["Month"], y = df["Profit"], errorbar = None, hue = "Year")
plt.title("Year and Month wise Profit")
plt.show()

"""It can be seen that there is most profit in month 3 and in year 2014

### **Q) In which month we have more profit with specific year graph ?**
"""

b_2013 = df[df["Year"]==2013]
b_2014 = df[df["Year"]==2014]
b_2015 = df[df["Year"]==2015]
b_2016 = df[df["Year"]==2016]

fig, ax = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Profit by Year', fontsize=22)

sns.barplot(data = b_2013, x = b_2013["Month"], y = b_2013["Profit"], errorbar = None, ax = ax[0,0])
sns.barplot(data = b_2014, x = b_2014["Month"], y = b_2014["Profit"], errorbar = None, ax = ax[0,1])
sns.barplot(data = b_2015, x = b_2015["Month"], y = b_2015["Profit"], errorbar = None, ax = ax[1,0])
sns.barplot(data = b_2016, x = b_2016["Month"], y = b_2016["Profit"], errorbar = None, ax = ax[1,1])

ax[0,0].title.set_text('Year 2013')
ax[0,1].title.set_text('Year 2014')
ax[1,0].title.set_text('Year 2015')
ax[1,1].title.set_text('Year 2016')


plt.show()

"""### **Q) Which Category & Sub-Category makes more profit ?**"""

sc = df.groupby(["Sub-Category"])["Profit"].sum()
sc = sc.sort_values(ascending = False).head().to_frame()
colors = ["skyblue", "orange", "lightgreen", "m", "c"]

fig, ax = plt.subplots(2, figsize = (10,10))

sns.barplot(data = df, x = "Category", y = "Profit", hue = "Category", errorbar = None, ax = ax[0])
ax[1].bar(sc.index, sc["Profit"], color = colors, label = sc.index)
ax[1].legend()
ax[1].set_xlabel("Sub-Category")
ax[1].set_ylabel("Profit")

ax[0].title.set_text('Profit by Category')
ax[1].title.set_text('Profit by Sub-Category')

plt.show()

"""Category Technology and Sub-Category Appliances makes more profit

### **Top 5 Customer who makes more profit ?**
"""

cus_pur = df.groupby(["Customer Name"])["Profit"].sum()
cus_pur = cus_pur.sort_values(ascending = False).head().to_frame()
sns.barplot(data = cus_pur, x = cus_pur["Profit"], y = cus_pur.index)
plt.title("Top 5 Customers who makes more profit")
plt.show()

"""#### **Scatter plots of numerical columns**"""

# Checking the column names
num_col

df.head(2)

"""#### **Pie Chart of Numerical Columns**"""

# Checking the categorical column names
cat_col

a3_ = a3.head()
a5_ = a5.head()

figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (10,8))

ax1.pie(a2.values, labels = a2.index, autopct = "%.2f%%")
ax1.legend(bbox_to_anchor = (1,1,0.4,0))
ax1.set_title("Category Count Percentage Distribution")

ax2.pie(a3_.values, labels = a3_.index, autopct = "%.2f%%")
ax2.legend(bbox_to_anchor = (1,1,0.4,0))
ax2.set_title("Country Count Percentage Distribution")

ax3.pie(a4.values, labels = a4.index, autopct = "%.2f%%")
ax3.legend(bbox_to_anchor = (1,1,0.4,0))
ax3.set_title("Segment Count Percentage Distribution")

ax4.pie(a5_.values, labels = a5_.index, autopct = "%.2f%%")
ax4.legend(bbox_to_anchor = (1,1,0.4,0))
ax4.set_title("Sub-Category Count Percentage Distribution")

plt.show()

"""#### **Boxplot**"""

print(cat_col)
print(num_col)

b1 = df["Customer Name"].value_counts().to_frame()
b2 = df["City"].value_counts().to_frame()
b3 = df["Country"].value_counts().to_frame()
b4 = df["Region"].value_counts().to_frame()
b5 = df["Segment"].value_counts().to_frame()
b6 = df["State"].value_counts().to_frame()
b7 = df["Product Name"].value_counts().to_frame()
b8 = df["Category"].value_counts().to_frame()
b9 = df["Sub-Category"].value_counts().to_frame()

fig, ax = plt.subplots(3, 3, figsize=(20, 10))
fig.suptitle('Boxplot', fontsize=22)

sns.boxplot(b1["Customer Name"], ax = ax[0,0])
sns.boxplot(b2["City"], ax = ax[0,1])
sns.boxplot(b3["Country"], ax = ax[0,2])
sns.boxplot(b4["Region"], ax = ax[1,0])
sns.boxplot(b5["Segment"], ax = ax[1,1])
sns.boxplot(b6["State"], ax = ax[1,2])
sns.boxplot(b7["Product Name"], ax = ax[2,0])
sns.boxplot(b8["Category"], ax = ax[2,1])
sns.boxplot(b9["Sub-Category"], ax = ax[2,2])

ax[0,0].title.set_text('Customer Name')
ax[0,1].title.set_text('City')
ax[0,2].title.set_text('Country')
ax[1,0].title.set_text('Region')
ax[1,1].title.set_text('Segment')
ax[1,2].title.set_text('State')
ax[2,0].title.set_text('Product Name')
ax[2,1].title.set_text('Category')
ax[2,2].title.set_text('Sub-Category')


plt.show()

fig, ax = plt.subplots(2, 2, figsize=(20, 10))
fig.suptitle('Sales - Boxplot', fontsize=22)

sns.boxplot(x = df.Sales, y = df["Category"], ax = ax[0,0])
sns.boxplot(x = df.Sales, y = df["Sub-Category"], ax = ax[0,1])
sns.boxplot(x = df.Sales, y = df["Segment"], ax = ax[1,0])
sns.boxplot(x = df.Sales, y = df["Country"], ax = ax[1,1])


ax[0,0].title.set_text('Category')
ax[0,1].title.set_text('Sub-Category')
ax[1,0].title.set_text('Segment')
ax[1,1].title.set_text('Country')


plt.show()

"""It can be seen that there are some outliers in our dataset"""

# plt.figure(figsize = (12,10))
sns.violinplot(y = df["Region"], x = df.Sales)
plt.ylabel("Region")
plt.title("Region based on Sales - Boxplot")
plt.show()

"""It can be seen that there are some outliers in our dataset

#### **Correlation on Heatmap**
"""

corr = df.corr()
corr

sns.heatmap(corr, annot = True, cmap = "coolwarm")
plt.title("Correlation of Numerical columns")
plt.show()

"""It can seen that there is negative or positive correlation between these columns. So, It is okay to be negative or positive correlation but it is not okay to be zero correlation

# **Encoding the Data (Data Preprocessing)**

#### **Make a copy of dataframe**
"""

# Make a copy of dataframe
df1 = df.copy()
print(df1.shape)
df1.head(5)

# Check the columns which we want to encode
df1.columns

# Select Columns for Using in next step
df1 = df1[['Customer Name', 'City', 'Country', 'Region','Segment', 'Ship Mode', 'State',
           'Product Name','Discount', 'Sales','Profit', 'Quantity', 'Category', 'Sub-Category']]

"""#### **Importing the libraries for encoding**"""

# Importing the libraries for encoding
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

"""#### **Check the columns which we want to encode**"""

# Check the columns which we want to encode
df1.columns

"""### **Encoding data with get dummies functions**"""

# Encoding data with get dummies
df1 = pd.get_dummies(df1, drop_first=True, columns = ['Customer Name', 'City', 'Country', 'Region', 'Segment', 'State', 'Product Name','Category', 'Sub-Category', 'Ship Mode'])
print(df1.shape)
df1.head(2)

"""# **Scaling**

**Import Libraries for Scaling Data**
"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler
ss = StandardScaler()
mms = MinMaxScaler()

df_scaled = mms.fit_transform(df1.to_numpy())
df_scaled = pd.DataFrame(df_scaled, columns=df1.columns)
df_scaled.head()

"""# **Selecting the x** (Dependent variable) **and the y** (Independent variable)"""

x = df1.drop(["Profit"], axis = 1)
y = df1['Profit']
print(x.shape)
print(y.shape)

"""# **Splitting the dataset into Training and Testing data**"""

# Importing Libraries for splitting data into Training and Testing
from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .15, random_state = 7)
print(xtrain.shape)
print(xtest.shape)
print(ytrain.shape)
print(ytest.shape)

"""# **Creating functions to evaluate the Regression Evaluation Metrics, Model Score**<br>

*Checking How much my model works efficiently*

#### **Importing Libraries**
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Creating functions for evaluating scores
def scores(ytest, ypred):
  mae = mean_absolute_error(ytest, ypred)
  mse = mean_squared_error(ytest, ypred)
  rmse = np.sqrt(mean_squared_error(ytest, ypred))
  r2 = r2_score(ytest, ypred)
  print("MAE: ", mae)
  print("MSE: ", mse)
  print("RMSE: ", rmse)
  print("R2 Score: ", r2)

def model_score(model):
  print("Training Score: ", model.score(xtrain, ytrain))
  print("Testing Score: ", model.score(xtest, ytest))

def adjusted_r2_score(ytest, y_pred, n_features):
    r_squared = r2_score(ytest, y_pred)
    adjusted_r_squared = 1 - (1 - r_squared) * (len(ytest) - 1) / (len(ytest) - n_features - 1)
    print("Adjusted R2 Score: ", adjusted_r_squared)

"""# **Importing the ML Regression Libraries**"""

from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.ensemble import BaggingClassifier, BaggingRegressor
from sklearn.multioutput import MultiOutputRegressor

"""### **1) Linear Regression**"""

lr = LinearRegression()
lr.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(lr)

"""Generate the predictions"""

ypred_lr = lr.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_lr)

adjusted_r2_score(ytest, ypred_lr, (df1.shape[1]-1))

"""### **2) Ridge Regression**"""

rr = Ridge(alpha=25)
rr.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(rr)

"""Generate the predictions"""

ypred_rr = rr.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_rr)

adjusted_r2_score(ytest, ypred_rr, (df1.shape[1]-1))

"""### **3) Lasso Regression**"""

lar = Lasso(alpha=0.1)
lar.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(lar)

"""Generate the predictions"""

ypred_lar = lar.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_lar)

adjusted_r2_score(ytest, ypred_lar, (df1.shape[1]-1))

"""### **4) KNeighborsRegressor**"""

knn = KNeighborsRegressor(n_neighbors = 15)
knn.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(knn)

"""Generate the predictions"""

ypred_knn = knn.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_knn)

adjusted_r2_score(ytest, ypred_knn, (df1.shape[1]-1))

"""### **5) Decision Tree Regression**"""

dtr = DecisionTreeRegressor(random_state = 7, max_depth=4)
dtr.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(dtr)

"""Generate the predictions"""

ypred_dtr = dtr.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_dtr)

adjusted_r2_score(ytest, ypred_dtr, (df1.shape[1]-1))

"""### **6) Bagging Regressor with Decision Tree Regression**"""

bag_dtr = BaggingRegressor(estimator = dtr, n_estimators = 15,
                              max_samples = xtrain.shape[0],
                            max_features = xtrain.shape[1],
                           random_state = 7)
bag_dtr.fit(xtrain, ytrain)

"""Checking the Training Score and Testing Score"""

model_score(bag_dtr)

"""Generate the predictions"""

ypred_bag_dtr = bag_dtr.predict(xtest)

"""Checking the Scores of our model"""

scores(ytest, ypred_bag_dtr)

adjusted_r2_score(ytest, ypred_bag_dtr, (df1.shape[1]-1))

"""# **Checking Errors using Plots**"""

# Creating variables for plotting errors
error_lr = [i for i in range(len(ypred_lr))]
error_rr = [i for i in range(len(ypred_rr))]
error_lar = [i for i in range(len(ypred_lar))]
error_knn = [i for i in range(len(ypred_knn))]
error_dtr = [i for i in range(len(ypred_dtr))]
error_bag_dtr = [i for i in range(len(ypred_bag_dtr))]
# error_mr = [i for i in range(len(ypred_mr))]

figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize = (15,8))

ax1.plot(error_lr, ytest-ypred_lr)
ax1.set_title("Error in Linear Regression")

ax2.plot(error_rr, ytest-ypred_rr)
ax2.set_title("Error in Ridge Regression")

ax3.plot(error_lar, ytest-ypred_lar)
ax3.set_title("Error in Lasso Regression")

ax4.plot(error_knn, ytest-ypred_knn)
ax4.set_title("Error in KNeighbors Regression")

ax5.plot(error_dtr, ytest-ypred_dtr)
ax5.set_title("Error in Decision Tree Regression")

ax6.plot(error_bag_dtr, ytest-ypred_bag_dtr)
ax6.set_title("Error in Bagging Decision Tree Regression")

# ax7.plot(error_mr, ytest-ypred_mr)
# ax7.set_title("Error in Multi Decision Tree Regression")


plt.show()

"""# **Creating Dataframe of Models Score**"""

all_model = {"Linear Reg":[mean_absolute_error(ytest, ypred_lr), mean_squared_error(ytest, ypred_lr), np.sqrt(mean_squared_error(ytest, ypred_lr)), r2_score(ytest, ypred_lr)],
             "Ridge Reg":[mean_absolute_error(ytest, ypred_rr), mean_squared_error(ytest, ypred_rr), np.sqrt(mean_squared_error(ytest, ypred_rr)), r2_score(ytest, ypred_rr)],
             "Lasso Reg":[mean_absolute_error(ytest, ypred_lar), mean_squared_error(ytest, ypred_lar), np.sqrt(mean_squared_error(ytest, ypred_lar)), r2_score(ytest, ypred_lar)],
             "KNeighbors Reg":[mean_absolute_error(ytest, ypred_knn), mean_squared_error(ytest, ypred_knn), np.sqrt(mean_squared_error(ytest, ypred_knn)), r2_score(ytest, ypred_knn)],
             "Decision Tree Reg":[mean_absolute_error(ytest, ypred_dtr), mean_squared_error(ytest, ypred_dtr), np.sqrt(mean_squared_error(ytest, ypred_dtr)), r2_score(ytest, ypred_dtr)],
             "Bagging with Decision Tree Reg":[mean_absolute_error(ytest, ypred_bag_dtr), mean_squared_error(ytest, ypred_bag_dtr), np.sqrt(mean_squared_error(ytest, ypred_bag_dtr)), r2_score(ytest, ypred_bag_dtr)]}

res = pd.DataFrame(all_model, index = ["MAE", "MSE", "RMSE", "R2 Score"])
res

"""*We can see that there are less error in Decision Tree Reg as compare to other algorithms. So, We can take Decision Tree Reg as our best model*

#### **Final model (Decision Tree Regression) based on Evaluation**
"""

model = DecisionTreeRegressor(random_state = 7, max_depth=30)
model.fit(x, y)

"""#### **Checking Scores of our best model**"""

model_score(model)

"""We can see that our model is much better than before.

#### **Generate predictions for best model**
"""

ypred = model.predict(x)

"""#### **Checking Scores for our best model**"""

scores(y, ypred)

adjusted_r2_score(y, ypred, (df1.shape[1]-1))

"""# **Importing Pickle Library for Saving and Loading Model**"""

import pickle

"""# **Saving the best model using Pickle**"""

pickle.dump(model,open('best_model.pkl','wb'))

"""
# **Collecting 20 Datapoints randomly from our dataset**"""

df_20 = df1.sample(20)
print(df_20.shape)

# Saving the Sample Dataset
df_20.to_csv("sample_dataset.csv")

df_20.head(2)

"""#### **Selecting Dependent and Independent Variable for randomly 20 points selecting dataset**"""

x_20 = df_20.drop(["Profit"], axis = 1)
y_20 = df_20['Profit']
print(x.shape)
print(y.shape)

"""#### **Splitting the data into Training and Testing for randomly 20 points selecting dataset**"""

xtrain_20, xtest_20, ytrain_20, ytest_20 = train_test_split(x_20, y_20, test_size = .15)
print(xtrain_20.shape)
print(ytrain_20.shape)
print(xtest_20.shape)
print(ytest_20.shape)

"""#### **Loading the best model using Pickle**"""

# Load the saved trained ML model
best_model_20 = pickle.load(open("/content/best_model.pkl", "rb"))
best_model_20

"""#### **Generate the Predictions for randomly 20 points selecting dataset**"""

ypred_20 = best_model_20.predict(xtest_20)

"""#### **Checking the Scores for randomly 20 points selecting dataset**"""

model_score(best_model_20)

scores(ytest_20, ypred_20)

adjusted_r2_score(ytest_20, ypred_20, (df_20.shape[1]-1))

"""# **Making Pipelines**

#### **Importing Libraries for Pipelines**
"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LinearRegression

"""#### **Splitting data into Training and Testing**"""

pipeline_df = df[['Customer Name', 'City', 'Country', 'Region','Segment', 'Ship Mode', 'State',
                  'Product Name','Discount', 'Sales','Profit', 'Quantity', 'Category', 'Sub-Category']]

X = pipeline_df.drop(["Profit"], axis = 1)
Y = pipeline_df['Profit']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.15, random_state=7)
print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

from sklearn.impute import SimpleImputer

integer_transformer = Pipeline(steps = [
    ('imputer', SimpleImputer(strategy = 'most_frequent')),
     ('scaler', MinMaxScaler())
     ])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(sparse = False, handle_unknown='ignore'))
    ])

"""# **Create Pipelines**"""

# Create Pipeline Object with best fit model
pipeline = Pipeline(steps = [("Preprocessor1", categorical_transformer), ("Preprocessor2", integer_transformer), ("model", model)], verbose = True)
pipeline

"""#### **Train the model**"""

# Fitting the model
pipeline.fit(X, Y)

"""#### **Generate the predictions**"""

# Generate the predictions
pipe_pred = pipeline.predict(X_test)

"""#### **Checking the score**"""

# Checking the R2 Score
r2_score(Y_test, pipe_pred)

# Checking the Adjusted R2 Score
adjusted_r2_score(Y_test, pipe_pred, (df.shape[1]-1))

"""# **Saving the pipeline model for using in Web App**"""

pickle.dump(pipeline,open('pipeline_model.pkl','wb'))

"""# **Web App**"""

# !pip install -q streamlit
# !npm install localtunnel

# !streamlit run /content/sales_dataset_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com

